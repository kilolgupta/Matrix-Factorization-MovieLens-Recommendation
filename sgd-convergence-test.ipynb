{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import io\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "alpha = 0.02\n",
    "u = 138493\n",
    "m = 27278\n",
    "ratings_file = \"ml-20m/ratings.csv\"\n",
    "\n",
    "# the below 6 files are corresponding to the 3 separate random folds while splitting train and test data\n",
    "train_ratings_file_1 = \"train_data.csv\"\n",
    "test_ratings_file_1 = \"test_data.csv\"\n",
    "\n",
    "train_ratings_file_2 = \"train_data-2.csv\"\n",
    "test_ratings_file_2 = \"test_data-2.csv\"\n",
    "\n",
    "train_ratings_file_3 = \"train_data-3.csv\"\n",
    "test_ratings_file_3 = \"test_data-3.csv\"\n",
    "movies_mapping_file = \"ml-20m/movies.csv\"\n",
    "\n",
    "# These are the values which provided the minimum value of avg. RMSE\n",
    "lambd = 0.02\n",
    "rank = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build movie dictionary with line no as numpy movie id ,its actual movie id as the key.\n",
    "def build_movies_dict(movies_file):\n",
    "    i = 0\n",
    "    movie_id_dict = {}\n",
    "    with io.open(movies_file, 'r', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            if i == 0:\n",
    "                i = i+1\n",
    "            else:\n",
    "                movieId = line.split(',')[0]\n",
    "                movie_id_dict[int(movieId)] = i-1\n",
    "                i = i+1\n",
    "    return movie_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function returns 3 dictionaries: train/test_data_dict, user_to_movie_dict and movie_to_user_dict\n",
    "# the user_to_movie_dict and movie_to_user_dict are used in the optim_calc_error\n",
    "def read_data_sgd_test(input_file, movies_dict):\n",
    "    # creating a dictionary, key: (user_id, movie_id), value: rating\n",
    "    X = {}\n",
    "    user_to_movie_dict = {}\n",
    "    movie_to_user_dict = {}\n",
    "\n",
    "    # because we don't have a header row now\n",
    "    i = 1\n",
    "\n",
    "    with open(input_file,'r') as f:\n",
    "        for line in f:\n",
    "\n",
    "            # to escape the header row\n",
    "            if i == 0:\n",
    "                i += 1\n",
    "            else:\n",
    "                user, movie_id, rating, timestamp = line.split(',')\n",
    "                m_id = movies_dict[int(movie_id)]\n",
    "\n",
    "                X[(int(user)-1, m_id)] = float(rating)\n",
    "                \n",
    "                u_id = int(user)-1\n",
    "                \n",
    "                if u_id in user_to_movie_dict:\n",
    "                    user_to_movie_dict[u_id].append(m_id)\n",
    "                else:\n",
    "                    user_to_movie_dict[u_id] = []\n",
    "                    user_to_movie_dict[u_id].append(m_id)\n",
    "                \n",
    "                if m_id in movie_to_user_dict:\n",
    "                    movie_to_user_dict[m_id].append(u_id)\n",
    "                else:\n",
    "                    movie_to_user_dict[m_id] = []\n",
    "                    movie_to_user_dict[m_id].append(u_id)\n",
    "                \n",
    "                i += 1\n",
    "    return X, user_to_movie_dict, movie_to_user_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_dict = build_movies_dict(movies_mapping_file)\n",
    "train_data_dict, train_user_to_movie_dict, train_movie_to_user_dict = read_data(train_ratings_file, movies_dict)\n",
    "test_data_dict, test_user_to_movie_dict, test_movie_to_user_dict = read_data(test_ratings_file, movies_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function calculates error overall data points from the scratch\n",
    "def calc_error(V, W, X):\n",
    "    error = 0\n",
    "    V_norm = LA.norm(V)\n",
    "    W_norm = LA.norm(W)\n",
    "    for key, value in X.items():\n",
    "        i = key[0]\n",
    "        j = key[1]\n",
    "        rating = value\n",
    "        error += np.power(rating - np.dot(V[i], W[j]), 2)\n",
    "\n",
    "    error += (lambd)*(np.power(V_norm, 2) + np.power(W_norm, 2))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function updates the given error corresponding to the u_id and m_id which have been updated using SGD\n",
    "def optim_calc_error(V_old, W_old, V_new, W_new, X, u_id, m_id, error):\n",
    "    \n",
    "    m_list = train_user_to_movie_dict[u_id]\n",
    "    u_list = train_movie_to_user_dict[m_id]  \n",
    "    \n",
    "    for m in m_list:\n",
    "        error = error - (np.power(X[u_id, m] - np.dot(V_old[u_id],W_old[m]), 2))\n",
    "        error = error + np.power(X[u_id, m] - np.dot(V_new[u_id],W_new[m]), 2)\n",
    "    \n",
    "    for u in u_list:\n",
    "        error = error - (np.power(X[u, m_id] - np.dot(V_old[u],W_old[m_id]), 2))\n",
    "        error = error + np.power(X[u, m_id] - np.dot(V_new[u],W_new[m_id]), 2)\n",
    "    \n",
    "    error = error - (lambd/2) * np.sum(np.power(V_old[u_id],2) + pow(W_old[m_id],2))\n",
    "    error = error + (lambd/2) * np.sum(np.power(V_new[u_id],2) + pow(W_new[m_id],2))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# v1 as per the experiment section of write-up\n",
    "def matrix_factor_sgd_v1(X):\n",
    "    V = np.random.rand(u, rank)\n",
    "    W = np.random.rand(m, rank)\n",
    "    \n",
    "    # we have to calculate the initial error which the optimal function will then update on\n",
    "    error = calc_error(V, W, X)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for key, value in X.items():\n",
    "            i = key[0]\n",
    "            j = key[1]\n",
    "            rating = value\n",
    "            eij = rating - np.dot(V[i], W[j])\n",
    "            \n",
    "            V_old = deepcopy(V)\n",
    "            W_old = deepcopy(W)\n",
    "\n",
    "            V_update = V[i] + alpha * (2.0 * eij * W[j] - (lambd*2.0 * V[i]))\n",
    "            W_update = W[j] + alpha * (2.0 * eij * V[i] - (lambd*2.0 * W[j]))\n",
    "\n",
    "            V[i] = V_update\n",
    "            W[j] = W_update\n",
    "            \n",
    "            print(optim_calc_error(V_old, W_old, V, W, X, i, j, error))\n",
    "            \n",
    "\n",
    "    return V, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# v2 as per the experiment section of write-up\n",
    "def matrix_factor_sgd_v2(X):\n",
    "    V = np.random.rand(u, rank)\n",
    "    W = np.random.rand(m, rank)\n",
    "    \n",
    "    for epoch in range(46):\n",
    "        for key, value in random.sample(X.items(), 1000):\n",
    "            i = key[0]\n",
    "            j = key[1]\n",
    "            rating = value\n",
    "            eij = rating - np.dot(V[i], W[j])\n",
    "\n",
    "            V_update = V[i] + alpha * (2.0 * eij * W[j] - (lambd*2.0 * V[i]))\n",
    "            W_update = W[j] + alpha * (2.0 * eij * V[i] - (lambd*2.0 * W[j]))\n",
    "\n",
    "            V[i] = V_update\n",
    "            W[j] = W_update\n",
    "            \n",
    "            print(calc_error(V, W, X))\n",
    "\n",
    "    return V, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_factor_sgd_v1(train_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_factor_sgd_v2(train_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the print statements of the above two function calls, I used that data to create learning curves which are provided in the pdf write-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
